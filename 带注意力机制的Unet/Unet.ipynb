{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-19T08:34:18.001117100Z",
     "start_time": "2024-03-19T08:34:14.821737800Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from typing import Union,Tuple,List\n",
    "from utils.activate import Swish\n",
    "from utils.TimeEmbedding import TimeEmbedding\n",
    "from utils.DownBlock import DownBlock\n",
    "from utils.DownSample_and_UpSample import DownSample,Upsample\n",
    "from utils.MiddleBlock import MiddleBlock\n",
    "from utils.UpBlock import UpBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    DDPM UNet的主体架构\n",
    "    \"\"\"\n",
    "    def __init__(self,image_channels:int=3,n_channels:int=64,\n",
    "                 ch_mults:Union[Tuple[int,...],List[int]]=(1,2,2,4),\n",
    "                 is_attn:Union[Tuple[bool,...],List[int]]=(False,False,True,True),\n",
    "                 n_blocks:int=2):\n",
    "        \"\"\"\n",
    "        \n",
    "        :param image_channels: 原始图片的channel数\n",
    "        :param n_channels: 在进UNet之前，会对原始图片做一次初步卷积，这是卷积完的通道数\n",
    "        :param ch_mults: Encoder下采样每一层out_channel的倍数\n",
    "        :param is_attn: 在Encoder下采样/Decoder上采样的每一层是否要在CNN做特征提取后再引入Attention\n",
    "        :param n_blocks: 在Encoder/Decoder的每一层，需要用多少个上采样以及下采样块\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        #在Encoder下采样/Decoder上采样过程中图像依次缩小/放大\n",
    "        #每次变动会产生一个新的图像分辨率\n",
    "        #这里指的就是不同图像分辨率的个数，也可以理解为Encoder/Decoder的层数\n",
    "        n_resolutions=len(ch_mults)\n",
    "        \n",
    "        #对原始图像做预处理\n",
    "        self.image_proj=nn.Conv2d(in_channels=image_channels,out_channels=n_channels,kernel_size=3,padding=1)\n",
    "        \n",
    "        #时间戳生成\n",
    "        self.time_emb=TimeEmbedding(n_channels*4)\n",
    "        \n",
    "        #定义Encoder部分\n",
    "        \n",
    "        #down列表中的每个元素表示Encoder的每一层\n",
    "        down=[]\n",
    "        \n",
    "        out_channels=in_channels=n_channels\n",
    "        \n",
    "        for i in range(n_resolutions):\n",
    "            \n",
    "            #根据设定好的规则，得到这一层的out_channel\n",
    "            out_channels=in_channels*ch_mults[i]\n",
    "            \n",
    "            #每一层有几个块\n",
    "            for _ in range(n_blocks):\n",
    "                down.append(DownBlock(in_channels,out_channels,n_channels*4,is_attn[i]))\n",
    "                in_channels=out_channels\n",
    "            \n",
    "            #对Encoder来言，每一层结束后都做一次下采样，但Encoder的最后一层不做下采样\n",
    "            if i<n_resolutions-1:\n",
    "                down.append(DownSample(in_channels))\n",
    "        \n",
    "        #将列表转化为网络\n",
    "        self.down=nn.ModuleList(down)\n",
    "        \n",
    "        #定义Middle部分\n",
    "        self.middle=MiddleBlock(out_channels,n_channels*4,)\n",
    "        \n",
    "        #定义Decoder部分\n",
    "        up=[]\n",
    "        in_channels=out_channels\n",
    "        \n",
    "        for i in reversed(range(n_resolutions)):\n",
    "            out_channels=in_channels\n",
    "            for _ in range(n_blocks):\n",
    "                up.append(UpBlock(in_channels,out_channels,n_channels*4,is_attn[i]))\n",
    "            \n",
    "            out_channels=in_channels//ch_mults[i]\n",
    "            up.append(UpBlock(in_channels,out_channels,n_channels*4,is_attn[i]))\n",
    "            in_channels=out_channels\n",
    "            if i>0:\n",
    "                up.append(Upsample(in_channels))\n",
    "        self.up=nn.ModuleList(up)\n",
    "        \n",
    "        #定义group_norm，激活函数以及最后一层CNN，将最上一层特征图还原为原始图\n",
    "        self.norm=nn.GroupNorm(8,n_channels)\n",
    "        self.act=Swish()\n",
    "        self.final=nn.Conv2d(in_channels,image_channels,kernel_size=3,padding=1)\n",
    "        \n",
    "    \n",
    "    def forward(self,x:torch.Tensor,t:torch.Tensor):\n",
    "        \"\"\"\n",
    "        \n",
    "        :param x: 输入数据xt，尺寸大小为(batch_size,in_channels,height,width)\n",
    "        :param t: 输入数据t，尺寸大小为(batch_size)\n",
    "        \"\"\"\n",
    "        t=self.time_emb(t)\n",
    "        \n",
    "        #对原始图片先做预处理\n",
    "        x=self.image_proj(x)\n",
    "        \n",
    "        #Encoder部分\n",
    "        h=[x]\n",
    "        \n",
    "        for m in self.down:\n",
    "            x=m(x,t)\n",
    "            h.append(x)\n",
    "        \n",
    "        #中间模块\n",
    "        x=self.middle(x,t)\n",
    "        \n",
    "        #解码器部分\n",
    "        for m in self.up:\n",
    "            if isinstance(m,Upsample):\n",
    "                x=m(x,t)\n",
    "            else:\n",
    "                s=h.pop()\n",
    "                x=torch.cat((x,s),dim=1)\n",
    "                x=m(x,t)\n",
    "        \n",
    "        return self.final(self.act(self.norm(x)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T08:34:20.808058100Z",
     "start_time": "2024-03-19T08:34:20.756531500Z"
    }
   },
   "id": "596d37e711820864"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12, 93, 98, 80,  9,  2, 91, 19,  0, 43, 28, 60,  1, 33, 20, 15,  6, 67,\n",
      "        59, 32, 20, 30, 92, 36, 25, 10, 80, 16, 90, 99, 40, 61, 82, 90,  1, 87,\n",
      "        84, 31,  7, 23, 51, 25, 86,  2, 53, 18, 12, 92, 19, 98, 21, 21, 45, 52,\n",
      "        42, 47, 37, 53, 73, 49, 23, 61, 34, 67, 60, 24, 53, 18, 87, 86, 95, 20,\n",
      "        74, 14, 62, 58, 36, 25, 72, 53, 50, 35, 89, 10, 68, 86, 16, 59, 17, 18,\n",
      "        34, 94, 85, 71, 67, 10, 15, 88, 28, 73, 36, 76,  4, 28, 95, 30, 46, 45,\n",
      "        60, 97, 21, 75,  7, 45, 58, 73, 23,  4, 31, 51, 49,  2,  0,  0, 60, 52,\n",
      "        16, 58,  6, 55, 82, 37, 93, 75, 62, 67, 69, 62,  3, 56, 49,  0, 95, 29,\n",
      "        27,  3, 68,  5, 72, 43, 21, 82, 75, 72, 84, 52, 52, 35, 40,  8, 96, 62,\n",
      "        56, 31, 42, 70, 10, 53, 79, 49, 21, 21, 13, 13, 92, 15, 44, 87, 95, 72,\n",
      "        81, 42, 57, 57, 58, 31, 29, 16, 52, 22, 20, 18,  1, 91, 87, 26, 21, 31,\n",
      "        28,  2, 44, 35, 58, 64, 67, 49, 26, 12, 31, 28,  9, 27, 66, 58, 99, 68,\n",
      "        47, 23, 75, 56, 45, 56, 50, 99, 61, 86, 88, 85, 56, 74, 44, 46, 79, 96,\n",
      "         9, 87, 36, 90, 24, 61, 17, 12, 54, 26,  6, 14,  4, 89, 25, 39, 21,  8,\n",
      "        86, 92, 31, 23])\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(size=[256,3,32,32])\n",
    "t=torch.randint(low=0,high=100,size=[256])\n",
    "print(t)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T08:34:22.929917400Z",
     "start_time": "2024-03-19T08:34:22.885983500Z"
    }
   },
   "id": "b3b3af2fc9ca8c11"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 64, 1, 1])\n",
      "torch.Size([256, 64, 1, 1])\n",
      "torch.Size([256, 128, 1, 1])\n",
      "torch.Size([256, 128, 1, 1])\n",
      "torch.Size([256, 256, 1, 1])\n",
      "torch.Size([256, 256, 1, 1])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.Size([256, 1024, 1, 1])\n",
      "torch.Size([256, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "unet=UNet()\n",
    "print(unet(x,t).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-19T08:38:05.186738900Z",
     "start_time": "2024-03-19T08:37:56.134581700Z"
    }
   },
   "id": "25964222809aa394"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "eebe02647ea0be13"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
