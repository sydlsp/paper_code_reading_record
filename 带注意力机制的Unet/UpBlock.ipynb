{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-15T09:48:55.050174700Z",
     "start_time": "2024-03-15T09:48:53.181307600Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from utils.Attention import AttentionBlock\n",
    "from utils.ResidualBlock import ResidualBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class UpBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    这一模块也是有残差块和注意力块结合而成的\n",
    "    \"\"\"\n",
    "    def __init__(self,in_channels:int,out_channels:int,time_channels:int,has_attn:bool):\n",
    "        super().__init__()\n",
    "        \n",
    "        #看Unet的示意图右边的部分是要和左边的结果接起来的\n",
    "        self.res=ResidualBlock(in_channels+out_channels,out_channels,time_channels)\n",
    "        if has_attn:\n",
    "            self.attn=AttentionBlock(out_channels)\n",
    "        else:\n",
    "            self.attn=nn.Identity()\n",
    "    \n",
    "    def forward(self,x:torch.Tensor,t:torch.Tensor):\n",
    "        \n",
    "        x=self.res(x,t)\n",
    "        x=self.attn(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49a967d8f75a944"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
